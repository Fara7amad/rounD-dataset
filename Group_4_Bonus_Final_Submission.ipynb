{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c78ba316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b8048",
   "metadata": {},
   "source": [
    "## Reading the tracks and tracks meta as a one dataframe for each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18868ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracksMetaPath = \"00_tracksMeta.csv\"    \n",
    "tracksMeta = pd.read_csv(tracksMetaPath)\n",
    "counter = tracksMeta[\"trackId\"].max() + 1\n",
    "for i in range(24):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if i < 10:\n",
    "        tracksMetaPath = tracksMetaPath.replace('0'+str(i-1), '0'+str(i))\n",
    "    if i >= 10: \n",
    "        tracksMetaPath = tracksMetaPath.replace(str(i-1), str(i))\n",
    "    if i == 10: \n",
    "        tracksMetaPath = tracksMetaPath.replace('0'+str(i), str(i))\n",
    "    toJoinFile = pd.read_csv(tracksMetaPath)\n",
    "    #Give a unique ID for each track who has a previously used  one                    \n",
    "    for j in range(toJoinFile[\"trackId\"].max() + 1):\n",
    "        toJoinFile[\"trackId\"].replace({j : counter}, inplace = True)        \n",
    "        counter = counter + 1\n",
    "    tracksMeta = pd.concat([tracksMeta, toJoinFile], axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a4e72f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracksPath = \"00_tracks.csv\"    \n",
    "tracks = pd.read_csv(tracksPath)\n",
    "counter = tracks[\"trackId\"].max() + 1\n",
    "for i in range(24):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if i < 10:\n",
    "        tracksPath = tracksPath.replace('0'+str(i-1), '0'+str(i))\n",
    "    if i >= 10: \n",
    "        tracksPath = tracksPath.replace(str(i-1), str(i))\n",
    "    if i == 10: \n",
    "        tracksPath = tracksPath.replace('0'+str(i), str(i))\n",
    "    toJoinFile = pd.read_csv(tracksPath)\n",
    "    #Give a unique ID for each track who has a previously used  one                    \n",
    "    for j in range(toJoinFile[\"trackId\"].max() + 1):\n",
    "        toJoinFile[\"trackId\"].replace({j : counter}, inplace = True)        \n",
    "        counter = counter + 1\n",
    "    tracks = pd.concat([tracks, toJoinFile], axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e2287e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all vehicles id\n",
    "vehicles = tracksMeta.copy()\n",
    "vehicles = vehicles[vehicles[\"class\"] != 'pedestrian']\n",
    "vehicles = vehicles[vehicles[\"class\"] != 'motorcycle']\n",
    "vehicles = vehicles[vehicles[\"class\"] != 'bicycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1cb0cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all pedestrian and bicycle id\n",
    "pede = tracksMeta[tracksMeta[\"class\"] == 'pedestrian'] \n",
    "pede = pd.concat([pede,tracksMeta[tracksMeta[\"class\"] == 'bicycle']], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee304006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all records for each object\n",
    "vehiclesData = pd.merge(vehicles['trackId'], tracks)\n",
    "pedeData = pd.merge(pede['trackId'], tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eadb4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the vehicles records that has the same time(frame and recording id) with any of the pedestrians or bicycles\n",
    "sameFrame = pd.merge(pedeData[['frame', 'recordingId']], vehiclesData)\n",
    "sameFrame.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f32a747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "2111\n"
     ]
    }
   ],
   "source": [
    "#Get the minimum and maximun xCenter values for each vehicle to check if any of the VRUs has the same\n",
    "minXC = sameFrame.groupby(['trackId', 'recordingId'])['xCenter'].min()\n",
    "maxXC = sameFrame.groupby(['trackId', 'recordingId'])['xCenter'].max() \n",
    "#Get tracksID and their number in each record  \n",
    "recordingSize = sameFrame.groupby(['recordingId'])['trackId'].nunique()\n",
    "recordingWithTrackId = sameFrame.groupby(['recordingId'])['trackId'].unique()\n",
    "counter = 0\n",
    "#vehicleId a list that will contain thee vehicles that has the same xCenter with a pedestrian or a bicycle\n",
    "vehiclesId = []  \n",
    "for j in range(23): \n",
    "    for k in range(recordingSize.iloc[j]):\n",
    "        if(pedeData[pedeData['recordingId'] == j ]['xCenter'].between(minXC.iloc[counter], maxXC.iloc[counter]).any()):\n",
    "            vehiclesId.append(recordingWithTrackId[j][k]) \n",
    "        counter = counter + 1 \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68861f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same process as the above cell\n",
    "minYC = sameFrame.groupby(['trackId', 'recordingId'])['yCenter'].min()\n",
    "maxYC = sameFrame.groupby(['trackId', 'recordingId'])['yCenter'].max()  \n",
    "recordingSize = sameFrame.groupby(['recordingId'])['trackId'].nunique()\n",
    "recordingWithTrackId = sameFrame.groupby(['recordingId'])['trackId'].unique()\n",
    "counter = 0\n",
    "vehiclesIdY = [] \n",
    "for j in range(23): \n",
    "    for k in range(recordingSize.iloc[j]): \n",
    "        if(Pede[Pede['recordingId'] == j ]['yCenter'].between(minYC.iloc[counter], maxYC.iloc[counter]).any()):\n",
    "            vehiclesIdY.append(recordingWithTrackId[j][k])\n",
    "        counter = counter + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bbd8a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the intersection between the result from  trackIds that \n",
    "vehiclesIds = np.intersect1d(np.array(vehiclesId), np.array(vehiclesIdY) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c95a6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the previosly calculated volatility measures for drivers\n",
    "volatilityMeasures = pd.read_csv(\"volatilityMeasures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c64b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the volatility measure for each interacted driver \n",
    "vehiclesIds = pd.DataFrame({'trackId':vehiclesIds})   \n",
    "filteredVehicle = pd.merge(volatilityMeasures, vehiclesIds['trackId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14ae0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing an outlier \n",
    "filteredVehicle.drop(index = 51, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6bf32ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the trackId column to use the data as an input to the KMeans model \n",
    "filteredVehicle.drop(columns = 'trackId', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5cace5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KMeans(n_clusters = 3)\n",
    "model.fit(filteredVehicle)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9e42f2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secModel = KMeans(n_clusters = 2)\n",
    "secModel.fit(filteredVehicle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d10e21b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.37539469e+00,  1.05633847e+00,  8.70753988e+01,\n",
       "         5.28385647e+01, -6.28239169e+01,  2.03310556e+00,\n",
       "         3.94207254e-01,  7.11136005e+01,  4.13809056e+01,\n",
       "        -5.16810035e+01,  2.05598486e+01,  2.52623284e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 6.94966278e+00,  8.45703880e-01,  3.22586087e+03,\n",
       "         6.69808078e+01, -6.24103262e+01,  6.52058952e+00,\n",
       "         4.39761564e-01,  1.20937194e+03,  5.21845079e+01,\n",
       "        -3.01139189e+01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 3.20988417e+00,  1.08173005e+00, -1.58857327e+02,\n",
       "         6.38684166e+01, -7.31102676e+01,  2.80419350e+00,\n",
       "         4.16434837e-01, -1.53161422e+02,  4.84157698e+01,\n",
       "        -5.77138657e+01,  5.93932489e-01,  9.25830455e-01,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cluster_centers_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "87674a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.70016897e+00,  1.06622060e+00, -8.63895940e+00,\n",
       "         5.71312638e+01, -6.68272534e+01,  2.33320465e+00,\n",
       "         4.02857989e-01, -1.61718137e+01,  4.41187987e+01,\n",
       "        -5.40289283e+01,  1.27893299e+01,  5.14628237e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 6.94966278e+00,  8.45703880e-01,  3.22586087e+03,\n",
       "         6.69808078e+01, -6.24103262e+01,  6.52058952e+00,\n",
       "         4.39761564e-01,  1.20937194e+03,  5.21845079e+01,\n",
       "        -3.01139189e+01,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secModel.cluster_centers_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1066da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
